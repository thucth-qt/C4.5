{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "\n",
    "\n",
    "def walk_dictionaryv2(graph, dictionary, parent_node=None):\n",
    "    '''\n",
    "    Recursive plotting function for the decision tree stored as a dictionary\n",
    "    '''\n",
    "\n",
    "    for k in dictionary.keys():\n",
    "\n",
    "        if parent_node is not None:\n",
    "\n",
    "            from_name = parent_node.get_name().replace(\"\\\"\", \"\") + '_' + str(k)\n",
    "            from_label = str(k)\n",
    "\n",
    "            node_from = pydot.Node(from_name, label=from_label)\n",
    "            graph.add_node(node_from)\n",
    "            graph.add_edge( pydot.Edge(parent_node, node_from) )\n",
    "\n",
    "            if isinstance(dictionary[k], dict): # if interim node\n",
    "\n",
    "\n",
    "                walk_dictionaryv2(graph, dictionary[k], node_from)\n",
    "\n",
    "            else: # if leaf node\n",
    "                to_name = str(k) + '_' + str(dictionary[k]) # unique name\n",
    "                to_label = str(dictionary[k])\n",
    "\n",
    "                node_to = pydot.Node(to_name, label=to_label, shape='box', style = 'filled', fillcolor = '#CCCDC6' if isinstance(dictionary[k], dict) else '#CCCDC6')\n",
    "                graph.add_node(node_to)\n",
    "                graph.add_edge(pydot.Edge(node_from, node_to))\n",
    "\n",
    "                #node_from.set_name(to_name)\n",
    "\n",
    "        else:\n",
    "\n",
    "            from_name =  str(k)\n",
    "            from_label = str(k)\n",
    "\n",
    "            node_from = pydot.Node(from_name, label=from_label)\n",
    "            walk_dictionaryv2(graph, dictionary[k], node_from)\n",
    "\n",
    "\n",
    "def plot_tree(tree, name):\n",
    "\n",
    "    # first you create a new graph, you do that with pydot.Dot()\n",
    "    graph = pydot.Dot(graph_type='graph')\n",
    "\n",
    "    walk_dictionaryv2(graph, tree)\n",
    "\n",
    "    graph.write_png(name+'.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/24657384/plotting-a-decision-tree-with-pydot\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Node:\n",
    "\t'''\n",
    "\tData structure is to store nodes of tree.\n",
    "\t'''\n",
    "\tdef __init__(self, is_leaf=False, criterion=None, label=\"\", threshold=None, pure_degree=\"\", correct_wrong=None, children=[]):\n",
    "\t\tself.criterion = criterion\n",
    "\t\tself.label = label\n",
    "\t\tself.threshold = threshold\n",
    "\t\tself.is_leaf = is_leaf\n",
    "\t\tself.children = children\n",
    "\t\tself.pure_degree = pure_degree\n",
    "\t\tself.correct_wrong = correct_wrong\n",
    "class C45:\n",
    "\t\"\"\"Creates a bi-decision tree with C4.5 algorithm\"\"\"\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.data = None\n",
    "\t\tself.classes = None\n",
    "\t\tself.numAttributes = None\n",
    "\t\tself.attributes = None\n",
    "\t\tself.tree = None\n",
    "\t\tself.tree_dict={}\n",
    "\n",
    "\tdef load_data(self, attributes, data, classes):\n",
    "\t\tself.data = data\n",
    "\t\tself.classes = classes\n",
    "\t\tself.numAttributes = len(attributes)\n",
    "\t\tself.attributes = attributes\n",
    "\n",
    "\tdef printTree(self):\n",
    "\t\t'''\n",
    "\t\tVisualize on console\n",
    "\t\t'''\n",
    "\t\tself.__printNode(self.tree)\n",
    "\t\n",
    "\tdef __printNode(self, node, indent=\"\"):\n",
    "\t\tif node.is_leaf: \n",
    "\t\t\treturn \n",
    "\t\t\n",
    "\t\tleftChild = node.children[0]\n",
    "\t\trightChild = node.children[1]\n",
    "\t\tif leftChild.is_leaf:\n",
    "\t\t\tprint(indent+\"|____\" + node.criterion + \" <= \" + str(node.threshold) + \" : \" + leftChild.label + \" (\" +str(leftChild.pure_degree)+ \")\")\n",
    "\t\telse:\n",
    "\t\t\tprint(indent+\"|____\" + node.criterion + \" <= \" + str(node.threshold))\n",
    "\t\tself.__printNode(leftChild, indent + \"|\t\")\n",
    "\t\t\n",
    "\t\tif rightChild.is_leaf:\n",
    "\t\t\tprint(indent+\"|____\" + node.criterion + \" > \" + str(node.threshold) + \" : \" + rightChild.label+ \" (\" + str(rightChild.pure_degree) + \")\")\n",
    "\t\t\tprint(indent)\n",
    "\t\telse:\n",
    "\t\t\tprint(indent+\"|____\" + node.criterion + \" > \" + str(node.threshold))\n",
    "\t\tself.__printNode(rightChild, indent + \"\t\")\n",
    "\t\n",
    "\tdef __generate_tree_dict(self):\n",
    "\t\t'''\n",
    "\t\tGenerate dictionary for visualizing in image\n",
    "\t\t'''\n",
    "\t\tself.tree_dict[self.tree.criterion] = self.__recursive_generate_tree_dict(self.tree)\n",
    "\t\n",
    "\tdef __recursive_generate_tree_dict(self, node:Node):\n",
    "\t\tif node.is_leaf:\n",
    "\t\t\treturn \n",
    "\n",
    "\t\tleftChild:Node = node.children[0]\n",
    "\t\trightChild:Node = node.children[1]\n",
    "\n",
    "\t\tbranch ={}\n",
    "\t\tif leftChild.is_leaf:\n",
    "\t\t\tbranch[\"<=\"+str(node.threshold)] = leftChild.label + \"\\n\"+str(round(leftChild.pure_degree,2)) + \"\\n\" +str(leftChild.correct_wrong)\n",
    "\t\telse:\n",
    "\t\t\tbranch[\"<=\"+str(node.threshold)] = {leftChild.criterion: self.__recursive_generate_tree_dict(leftChild)}\n",
    "\t\t\n",
    "\t\tif rightChild.is_leaf:\n",
    "\t\t\tbranch[\">\"+str(node.threshold)] = rightChild.label+ \"\\n\"+str(round(rightChild.pure_degree,2))+ \"\\n\" +str(rightChild.correct_wrong)\n",
    "\t\telse:\n",
    "\t\t\tbranch[\">\"+str(node.threshold)] = {rightChild.criterion: self.__recursive_generate_tree_dict(rightChild)}\n",
    "\n",
    "\t\treturn branch\n",
    "\t\n",
    "\tdef draw_tree(self, name):\n",
    "\t\t'''\n",
    "\t\tinput: \n",
    "\t\t\tname: name of image of tree \n",
    "\t\tvisualize tree with image named \"name\"\n",
    "\t\t'''\n",
    "\t\tself.__generate_tree_dict()\n",
    "\t\tplot_tree(self.tree_dict, name)\n",
    "\n",
    "\tdef generate_tree(self, is_prune=False):\n",
    "\t\t'''\n",
    "\t\trun generating tree from data.\n",
    "\t\tInput:\n",
    "\t\t\tis_prune: prune the leaf if two branches are the same label\n",
    "\t\t'''\n",
    "\t\tself.tree = self.__recursiveGenerateTree(curData=self.data, curAttributes=self.attributes,  is_prune=is_prune)\n",
    "\n",
    "\tdef __recursiveGenerateTree(self, curData=None, curAttributes=None, criterion=None, threshold=None, is_prune=False):\n",
    "\t\tif len(curData) == 0:\n",
    "\t\t\t#No any data sample for this curAttributes. (only in decrete criterion)\n",
    "\t\t\treturn None\n",
    "\n",
    "\t\tis_pure, class_ = self.__allSameClass(curData)\n",
    "\t\tif is_pure:\n",
    "\t\t\treturn Node(is_leaf=True, criterion=criterion, label=class_, pure_degree=100.0, correct_wrong=(len(curData), len(curData)-len(curData)))\n",
    "\t\telif len(curAttributes) == 0:\n",
    "\t\t\tmain_class, pure_degree, true_class_num = self.get_main_class(curData)\n",
    "\t\t\treturn Node(is_leaf=True, criterion=criterion, label=main_class, pure_degree=pure_degree, correct_wrong=(true_class_num, len(curData) - true_class_num))\n",
    "\t\telse:\n",
    "\t\t\t(best_attr, threshold_, Sis) = self.__split_data(curData, curAttributes)\n",
    "\t\t\tremainingAttributes = curAttributes[:]\n",
    "\t\t\tremainingAttributes.remove(best_attr)\n",
    "\t\t\tchildren = [self.__recursiveGenerateTree(Si, remainingAttributes, criterion=best_attr, threshold=threshold_, is_prune=is_prune) for Si in Sis]\n",
    "\t\t\tif len(children)==1:\n",
    "\t\t\t\tnode=children[0]\n",
    "\t\t\t\tnode.criterion=criterion\n",
    "\t\t\t\tnode.threshold = threshold\n",
    "\t\t\t\t\n",
    "\t\t\telif (is_prune and children[0].is_leaf==True \n",
    "\t\t\t\tand children[1].is_leaf==True \n",
    "\t\t\t\tand children[0].label==children[1].label):\n",
    "\n",
    "\t\t\t\tcorrect_wrong = (children[0].correct_wrong[0] + children[1].correct_wrong[0], children[0].correct_wrong[1]+children[1].correct_wrong[1])\n",
    "\t\t\t\tnode = Node(is_leaf=True, criterion=None,\n",
    "\t\t\t\t\t\t\tlabel=children[0].label,\n",
    "\t\t\t\t            children=[], pure_degree=correct_wrong[0]/(correct_wrong[0]+correct_wrong[1]),\n",
    "                            correct_wrong=correct_wrong)\n",
    "\t\t\telse:\n",
    "\t\t\t\tnode = Node(is_leaf=False, criterion=best_attr, threshold=threshold_, children=children)\n",
    "\t\t\treturn node\n",
    "\n",
    "\tdef get_main_class(self, S):\n",
    "\t\t'''\n",
    "\t\t\tThere is no attribute left. So vote the main label for current data set.\n",
    "\t\t\tInput: \n",
    "\t\t\t\tS: current data set.\n",
    "\t\t\t\n",
    "\t\t'''\n",
    "\t\tlabels = [row[-1] for row in S]\n",
    "\t\tclasses, count = np.unique(labels, return_counts=True)\n",
    "\t\tmax_idx = np.argmax(count)\n",
    "\t\tpure_degree = round(count[max_idx]/sum(count)*100, ndigits=2)\n",
    "\t\treturn classes[max_idx], pure_degree, np.max(count)\n",
    "\n",
    "\tdef __allSameClass(self, data):\n",
    "\t\t'''\n",
    "\t\t\tCheck if all rows is the same class\n",
    "\t\t\tInput:\n",
    "\t\t\t\tdata: current data\n",
    "\t\t\tReturn:\n",
    "\t\t\t\tFalse: different classes\n",
    "\t\t\t\tClass_name: if all rows are the same class\n",
    "\t\t'''\n",
    "\t\tfor row in data:\n",
    "\t\t\tif row[-1] != data[0][-1]:\n",
    "\t\t\t\treturn False, None\n",
    "\t\treturn True, data[0][-1]\n",
    "\n",
    "\tdef __split_data(self, data, attributes):\n",
    "\t\t'''\n",
    "\t\t\tuse decision tree algorithm to create tree.\n",
    "\t\t\tInput:\n",
    "\t\t\t\tcurData: remain data set.\n",
    "\t\t\t\tcurAtt\n",
    "\t\t'''\n",
    "\t\t#initialize\t\t\n",
    "\t\tmaxEnt = -1*float(\"inf\")\n",
    "\t\tbest_attribute = attributes[0]\n",
    "\t\tindexOfAttribute = self.attributes.index(best_attribute)\n",
    "\t\tbest_threshold = data[0][indexOfAttribute]\n",
    "\t\tsplitted = [data]\n",
    "\n",
    "\t\tfor attribute in attributes:\n",
    "\t\t\tindexOfAttribute = self.attributes.index(attribute)\n",
    "\t\n",
    "\t\t\tdata.sort(key = lambda x: x[indexOfAttribute])\n",
    "\t\t\tfor j in range(0, len(data) - 1):\n",
    "\t\t\t\tif data[j][indexOfAttribute] != data[j+1][indexOfAttribute]:\n",
    "\t\t\t\t\tthreshold = data[j][indexOfAttribute]\n",
    "\t\t\t\t\tless = []\n",
    "\t\t\t\t\tgreater = []\n",
    "\t\t\t\t\tfor row in data:\n",
    "\t\t\t\t\t\tif(row[indexOfAttribute] > threshold):\n",
    "\t\t\t\t\t\t\tgreater.append(row)\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tless.append(row)\n",
    "\t\t\t\t\te = self.gain(data, [less, greater])\n",
    "\t\t\t\t\tif e >= maxEnt:\n",
    "\t\t\t\t\t\tsplitted = [less, greater]\n",
    "\t\t\t\t\t\tmaxEnt = e\n",
    "\t\t\t\t\t\tbest_attribute = attribute\n",
    "\t\t\t\t\t\tbest_threshold = threshold\n",
    "\t\treturn (best_attribute,best_threshold,splitted)\n",
    "\n",
    "\tdef gain(self,S, Sis):\n",
    "\t\tE_S = self.entropy(S)\n",
    "\t\t\n",
    "\t\tif len(Sis[0])==0 or len(Sis[1])==0:\n",
    "\t\t\treturn E_S-0\n",
    "\n",
    "\t\ttotal_E_Si = sum([len(Si)/len(S)*self.entropy(Si)  for Si in Sis])\n",
    "\n",
    "\t\tGain = E_S - total_E_Si\n",
    "\t\treturn Gain\n",
    "\n",
    "\tdef entropy(self, S):\n",
    "\t\tlabels = [row[-1] for row in S]\n",
    "\t\tS = len(labels)\n",
    "\n",
    "\t\t_,Si = np.unique(labels, return_counts=True)\n",
    "\t\tSi = list(Si)\n",
    "\t\tentropy = -sum([si_/S * math.log(si_/S,2) for si_ in Si])\n",
    "\t\t\n",
    "\t\treturn entropy\n",
    "\n",
    "\tdef fit(self, data):\n",
    "\t\t'''\n",
    "\t\tthis function is to predict with given data.\n",
    "\t\t\n",
    "\t\tInput:\n",
    "\t\t\tdata: one sample, example: [10,20,16,5,51]\n",
    "\t\tReturn: \n",
    "\t\t\tlabel of this sample. Example: \"Yes\"\n",
    "\t\t'''\n",
    "\t\tnode: Node = self.tree\n",
    "\t\tconsidered_attr = 0\n",
    "\t\twhile (considered_attr < self.numAttributes):\n",
    "\t\t\tif len(node.children) == 0:\n",
    "\t\t\t\treturn node.label\n",
    "\t\t\tconsidered_attr += 1\n",
    "\t\t\tidx_attr = self.attributes.index(node.criterion)\n",
    "\t\t\tif (data[idx_attr] <= node.threshold):\n",
    "\t\t\t\tnode = node.children[0]\n",
    "\t\t\telse:\n",
    "\t\t\t\tnode = node.children[1]\n",
    "\t\treturn node.label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "class Loader:\n",
    "    '''\n",
    "    This class is to load data and feed data into model (C4.5)\n",
    "    '''\n",
    "    def __init__(self, path_to_data:str, attributes: list, class_col:str, val_ratio:int=0.1):\n",
    "        '''\n",
    "            Input:\n",
    "                path_to_data: directory containing data\n",
    "                attributes: list of strings that column name. Example [\"HK01\", \"HK02\"]\n",
    "                class_col: String that is Name of column contain label.\n",
    "                val_ratio: val / data_total, this will divide data_total into training and validation set.\n",
    "\n",
    "        '''\n",
    "        self.filePathToData = path_to_data\n",
    "        self.val_ratio = val_ratio\n",
    "        self.attributes = attributes\n",
    "        self.class_col = class_col\n",
    "        self.classes=None\n",
    "        self.num_attributes = len(attributes)\n",
    "        self.data_total=None\n",
    "        self.vals = []\n",
    "        self.datas = []\n",
    "\n",
    "        self.__load_data()\n",
    "        self.__split_dataset()\n",
    "    \n",
    "    def __load_data(self):\n",
    "        df = pd.read_excel(self.filePathToData, sheet_name=0, index_col=None, header=0, usecols=self.attributes+[self.class_col])\n",
    "        self.data_total = df.values.tolist()\n",
    "        self.classes = list(set(df.iloc[:, -1]))\n",
    "\n",
    "    def __split_dataset(self):\n",
    "        # random.shuffle(self.data_total)\n",
    "        val_ = int(self.val_ratio*10)\n",
    "        data_ = 10 - val_\n",
    "        part_ = len(self.data_total)//(val_+data_)\n",
    "        data_pad = self.data_total+self.data_total\n",
    "        for part in range(val_+data_ -1):\n",
    "            self.vals.append(data_pad[part*part_:(part+val_)*part_])\n",
    "            self.datas.append(data_pad[(part+val_)*part_:(part+val_+data_)*part_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    '''\n",
    "    This class is to make training data with different methods.\n",
    "    main function of this class: train()\n",
    "    '''\n",
    "    def __init__ (self, model, data_loader):\n",
    "        self.model=model\n",
    "        self.data_loader = data_loader\n",
    "\n",
    "    def train(self, is_k_fold=False, prune=False):\n",
    "        '''\n",
    "            Input:\n",
    "                is_k_fold: if True, data will devide into k  parts, fold these parts during training, then compute average acc.\n",
    "                prune: if True, we will prune last leaf, that means we will merge two branches if they are the same label.\n",
    "        '''\n",
    "        model = self.model\n",
    "        if not is_k_fold:\n",
    "            model.load_data(attributes=self.data_loader.attributes,\n",
    "                                 data=self.data_loader.datas[0], classes=self.data_loader.classes)\n",
    "            model.generate_tree(prune)\n",
    "            acc = self.__validate(model, self.data_loader.vals[0])\n",
    "            return model, acc\n",
    "        else:\n",
    "            best_k_fold_acc=-1\n",
    "            best_model=None\n",
    "            best_acc=None\n",
    "            best_attrs=[]\n",
    "\n",
    "            for num_attr in range(1,len(self.data_loader.attributes)+1):\n",
    "                best_model_, best_acc_, k_fold_acc_ = self.__k_fold_validate(\n",
    "                    model, self.data_loader.attributes[:num_attr], prune)\n",
    "                if best_k_fold_acc < k_fold_acc_:\n",
    "                    best_k_fold_acc = k_fold_acc_\n",
    "                    best_model = best_model_\n",
    "                    best_acc = best_acc_\n",
    "                    best_attrs = self.data_loader.attributes[:num_attr]\n",
    "            return best_k_fold_acc, best_model, best_acc, best_attrs\n",
    "\n",
    "    def __validate(self, model, val):\n",
    "        '''\n",
    "        compute accuracy of model. \n",
    "        \n",
    "        Return:\n",
    "            number of true prediction / total prediction\n",
    "        '''\n",
    "        hit=0\n",
    "        for example in val:\n",
    "            data = example[:-1]\n",
    "            label = example[-1]\n",
    "            predict = model.fit(data)\n",
    "            if (predict == label):\n",
    "                hit+=1\n",
    "        return hit/len(val)\n",
    "    \n",
    "    def __k_fold_validate(self, model, attrs, prune=False):\n",
    "        scores = []\n",
    "        best_model = None\n",
    "        best_acc = -1\n",
    "        for data, val in zip(self.data_loader.datas, self.data_loader.vals):\n",
    "            model_ = model\n",
    "            model_.load_data(attributes=attrs,\n",
    "                            data=data, classes=self.data_loader.classes)\n",
    "            model_.generate_tree(prune)\n",
    "            acc = self.__validate(model_, val)\n",
    "            scores.append(acc)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                best_model = model_\n",
    "        k_fold_acc = sum(scores)/len(scores)\n",
    "        return best_model, best_acc, k_fold_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "|____first4semesters <= 53\n",
      "|\t|____HK04 <= 10 : No (100.0)\n",
      "|\t|____HK04 > 10\n",
      "|\t\t|____HK01 <= 15 : No (100.0)\n",
      "|\t\t|____HK01 > 15\n",
      "|\t\t\t|____HK03 <= 9\n",
      "|\t\t\t|\t|____HK02 <= 4 : No (100.0)\n",
      "|\t\t\t|\t|____HK02 > 4 : Yes (100.0)\n",
      "|\t\t\t|\t\n",
      "|\t\t\t|____HK03 > 9 : Yes (100.0)\n",
      "|\t\t\t\n",
      "|____first4semesters > 53\n",
      "\t|____HK01 <= 16\n",
      "\t|\t|____HK03 <= 25\n",
      "\t|\t|\t|____HK02 <= 14 : No (0.875)\n",
      "\t|\t|\t|____HK02 > 14\n",
      "\t|\t|\t\t|____HK04 <= 18 : Yes (63.64)\n",
      "\t|\t|\t\t|____HK04 > 18 : No (100.0)\n",
      "\t|\t|\t\t\n",
      "\t|\t|____HK03 > 25\n",
      "\t|\t\t|____HK02 <= 11 : No (50.0)\n",
      "\t|\t\t|____HK02 > 11 : Yes (100.0)\n",
      "\t|\t\t\n",
      "\t|____HK01 > 16\n",
      "\t\t|____HK02 <= 12\n",
      "\t\t|\t|____HK04 <= 17 : No (0.6666666666666666)\n",
      "\t\t|\t|____HK04 > 17 : Yes (100.0)\n",
      "\t\t|\t\n",
      "\t\t|____HK02 > 12 : Yes (0.84375)\n",
      "\t\t\n",
      "|____first4semesters <= 53\n",
      "|\t|____HK04 <= 10 : No (100.0)\n",
      "|\t|____HK04 > 10\n",
      "|\t\t|____HK01 <= 16 : No (100.0)\n",
      "|\t\t|____HK01 > 16\n",
      "|\t\t\t|____HK03 <= 9\n",
      "|\t\t\t|\t|____HK02 <= 4 : No (100.0)\n",
      "|\t\t\t|\t|____HK02 > 4 : Yes (100.0)\n",
      "|\t\t\t|\t\n",
      "|\t\t\t|____HK03 > 9 : Yes (100.0)\n",
      "|\t\t\t\n",
      "|____first4semesters > 53\n",
      "\t|____HK02 <= 13\n",
      "\t|\t|____HK01 <= 16\n",
      "\t|\t|\t|____HK03 <= 24 : No (0.8823529411764706)\n",
      "\t|\t|\t|____HK03 > 24\n",
      "\t|\t|\t\t|____HK04 <= 17 : No (50.0)\n",
      "\t|\t|\t\t|____HK04 > 17 : Yes (100.0)\n",
      "\t|\t|\t\t\n",
      "\t|\t|____HK01 > 16\n",
      "\t|\t\t|____HK04 <= 20\n",
      "\t|\t\t|\t|____HK03 <= 18 : No (87.5)\n",
      "\t|\t\t|\t|____HK03 > 18 : Yes (58.33)\n",
      "\t|\t\t|\t\n",
      "\t|\t\t|____HK04 > 20\n",
      "\t|\t\t\t|____HK03 <= 20 : Yes (100.0)\n",
      "\t|\t\t\t|____HK03 > 20 : No (100.0)\n",
      "\t|\t\t\t\n",
      "\t|____HK02 > 13\n",
      "\t\t|____HK01 <= 16\n",
      "\t\t|\t|____HK03 <= 20 : Yes (0.8333333333333334)\n",
      "\t\t|\t|____HK03 > 20 : No (0.6363636363636364)\n",
      "\t\t|\t\n",
      "\t\t|____HK01 > 16 : Yes (0.8854166666666666)\n",
      "\t\t\n",
      "Input 1: [22, 10, 20, 10, 62] preddict 1: No\n",
      "Input 2: [22, 10, 20, 10, 62] preddict 2: Yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loader = Loader(path_to_data=\"All.xlsx\", \n",
    "                attributes=[\"HK01\", \"HK02\", \"HK03\", \"HK04\",\"first4semesters\"], \n",
    "                class_col=\"Graduation\", \n",
    "                val_ratio=0.2)\n",
    "\n",
    "#k fold\n",
    "c1 = C45()\n",
    "trainer1 = Trainer(c1, loader)\n",
    "best_k_fold_acc, best_model, best_acc, best_attrs = trainer1.train(is_k_fold=True,prune=True)\n",
    "\n",
    "best_model.printTree()\n",
    "best_model.draw_tree(\"tree k-fold\")\n",
    "\n",
    "#Non k fold\n",
    "c2 = C45()\n",
    "trainer2 = Trainer(c2, loader)\n",
    "c2, acc = trainer2.train(is_k_fold=False, prune=True)\n",
    "\n",
    "c2.printTree()\n",
    "c2.draw_tree(\"tree non k-fold\")\n",
    "\n",
    "#predict\n",
    "input = [22, 10, 20, 10, 62]\n",
    "predict1 = c1.fit(input)\n",
    "predict2 = c2.fit(input)\n",
    "\n",
    "print(\"Input 1: {} preddict 1: {}\".format(input, predict1))\n",
    "print(\"Input 2: {} preddict 2: {}\".format(input, predict2))\n",
    "\n"
   ]
  }
 ]
}